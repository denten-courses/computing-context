{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 4: Style I\n",
    "\n",
    "## Screencasts\n",
    "\n",
    "https://drive.google.com/drive/u/1/folders/0B4OAOue0b3VMOU1yYW1JcUlNcWM",
    "\n",
    "## Readings\n",
    "\n",
    "- E.A. Smith. [Automated Readability Index](https://github.com/denten-courses/computing-context/blob/master/readings/ari.pdf), 1967.\n",
    "- Stubbs, Michael. “[Conrad in the Computer: Examples of Quantitative Stylistic Methods](http://lal.sagepub.com/content/14/1/5.full.pdf+html).” Language and Literature 14, no. 1 (February 1, 2005): 5–24.\n",
    "- Fish, Stanley E. “[What Is Stylistics and Why Are They Saying Such Terrible Things about It?-Part II](http://www.jstor.org/stable/303144).” Boundary 2 8, no. 1 (1979): 129–46.\n",
    "\n",
    "## Home Experiment\n",
    "\n",
    "- [Writers Battle](https://github.com/denten-courses/computing-context/blob/master/experiments/5-experiment/battle.md)\n",
    "\n",
    "## Lecture Notes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "text = '''\n",
    "The titular threat of The Blob has always struck me as the ultimate movie\n",
    "monster: an insatiably hungry, amoeba-like mass able to penetrate\n",
    "virtually any safeguard, capable of--as a doomed doctor chillingly\n",
    "describes it--\"assimilating flesh on contact.\n",
    "Snide comparisons to gelatin be damned, it's a concept with the most\n",
    "devastating of potential consequences, not unlike the grey goo scenario\n",
    "proposed by technological theorists fearful of\n",
    "artificial intelligence run rampant.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blob = TextBlob(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "blob?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "textblob.blob.TextBlob"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(blob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# automated readability index (ARI) \n",
    "# (4.71 * characters/words) + (0.5 * words/sentences) - 21.43\n",
    "\n",
    "words = blob.words\n",
    "chars = blob.string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['The', 'titular', 'threat', 'of', 'The', 'Blob', 'has', 'always', 'struck', 'me', 'as', 'the', 'ultimate', 'movie', 'monster', 'an', 'insatiably', 'hungry', 'amoeba-like', 'mass', 'able', 'to', 'penetrate', 'virtually', 'any', 'safeguard', 'capable', 'of', 'as', 'a', 'doomed', 'doctor', 'chillingly', 'describes', 'it', 'assimilating', 'flesh', 'on', 'contact', 'Snide', 'comparisons', 'to', 'gelatin', 'be', 'damned', 'it', \"'s\", 'a', 'concept', 'with', 'the', 'most', 'devastating', 'of', 'potential', 'consequences', 'not', 'unlike', 'the', 'grey', 'goo', 'scenario', 'proposed', 'by', 'technological', 'theorists', 'fearful', 'of', 'artificial', 'intelligence', 'run', 'rampant'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe titular threat of The Blob has always struck me as the ultimate movie\\nmonster: an insatiably hungry, amoeba-like mass able to penetrate\\nvirtually any safeguard, capable of--as a doomed doctor chillingly\\ndescribes it--\"assimilating flesh on contact.\\nSnide comparisons to gelatin be damned, it\\'s a concept with the most\\ndevastating of potential consequences, not unlike the grey goo scenario\\nproposed by technological theorists fearful of\\nartificial intelligence run rampant.\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "textblob.blob.WordList"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what type of object is words\n",
    "type(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what type of object is chards\n",
    "type(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get length of words\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hmm, do we trust the len? lets check. looks good!\n",
    "test = TextBlob(\"two words\")\n",
    "len(test.words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# good ol' blob has everything we need\n",
    "sents = blob.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentence(\"\n",
       " The titular threat of The Blob has always struck me as the ultimate movie\n",
       " monster: an insatiably hungry, amoeba-like mass able to penetrate\n",
       " virtually any safeguard, capable of--as a doomed doctor chillingly\n",
       " describes it--\"assimilating flesh on contact.\"),\n",
       " Sentence(\"Snide comparisons to gelatin be damned, it's a concept with the most\n",
       " devastating of potential consequences, not unlike the grey goo scenario\n",
       " proposed by technological theorists fearful of\n",
       " artificial intelligence run rampant.\n",
       " \")]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lets clean things up\n",
    "# automated readability index (ARI) \n",
    "# (4.71 * characters/words) + (0.5 * words/sentences) - 21.43\n",
    "\n",
    "num_chars = len(blob.string)\n",
    "num_words = len(blob.words)\n",
    "num_sents = len (blob.sentences)\n",
    "\n",
    "ari = 4.71 * num_chars/num_words + 0.5 * num_words/num_sents - 21.43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.904583333333335"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ari"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Interlude\n",
    "\n",
    "We have a number! What does it mean? How to verify models? The problem of ground truth. Garbage in, garbage out. What is stylistics and why are people saying such terrible things about it. Four ways to get at the ground truth:\n",
    "\n",
    "1. Expert opinion\n",
    "2. Laypeople opinion\n",
    "3. A tagged corpus\n",
    "4. Artificial corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'blob' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-d945b1f5e39e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# we pick up here next week!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# words, tokens, lemmas, n-grams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mblob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'blob' is not defined"
     ]
    }
   ],
   "source": [
    "# we pick up here next week!\n",
    "# words, tokens, lemmas, n-grams\n",
    "blob.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['The', 'titular', 'threat', 'of', 'The', 'Blob', 'has', 'always', 'struck', 'me', 'as', 'the', 'ultimate', 'movie', 'monster', ':', 'an', 'insatiably', 'hungry', ',', 'amoeba-like', 'mass', 'able', 'to', 'penetrate', 'virtually', 'any', 'safeguard', ',', 'capable', 'of', '--', 'as', 'a', 'doomed', 'doctor', 'chillingly', 'describes', 'it', '--', \"''\", 'assimilating', 'flesh', 'on', 'contact', '.', 'Snide', 'comparisons', 'to', 'gelatin', 'be', 'damned', ',', 'it', \"'s\", 'a', 'concept', 'with', 'the', 'most', 'devastating', 'of', 'potential', 'consequences', ',', 'not', 'unlike', 'the', 'grey', 'goo', 'scenario', 'proposed', 'by', 'technological', 'theorists', 'fearful', 'of', 'artificial', 'intelligence', 'run', 'rampant', '.'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WordList(['The', 'titular']),\n",
       " WordList(['titular', 'threat']),\n",
       " WordList(['threat', 'of']),\n",
       " WordList(['of', 'The']),\n",
       " WordList(['The', 'Blob']),\n",
       " WordList(['Blob', 'has']),\n",
       " WordList(['has', 'always']),\n",
       " WordList(['always', 'struck']),\n",
       " WordList(['struck', 'me']),\n",
       " WordList(['me', 'as']),\n",
       " WordList(['as', 'the']),\n",
       " WordList(['the', 'ultimate']),\n",
       " WordList(['ultimate', 'movie']),\n",
       " WordList(['movie', 'monster']),\n",
       " WordList(['monster', 'an']),\n",
       " WordList(['an', 'insatiably']),\n",
       " WordList(['insatiably', 'hungry']),\n",
       " WordList(['hungry', 'amoeba-like']),\n",
       " WordList(['amoeba-like', 'mass']),\n",
       " WordList(['mass', 'able']),\n",
       " WordList(['able', 'to']),\n",
       " WordList(['to', 'penetrate']),\n",
       " WordList(['penetrate', 'virtually']),\n",
       " WordList(['virtually', 'any']),\n",
       " WordList(['any', 'safeguard']),\n",
       " WordList(['safeguard', 'capable']),\n",
       " WordList(['capable', 'of']),\n",
       " WordList(['of', 'as']),\n",
       " WordList(['as', 'a']),\n",
       " WordList(['a', 'doomed']),\n",
       " WordList(['doomed', 'doctor']),\n",
       " WordList(['doctor', 'chillingly']),\n",
       " WordList(['chillingly', 'describes']),\n",
       " WordList(['describes', 'it']),\n",
       " WordList(['it', 'assimilating']),\n",
       " WordList(['assimilating', 'flesh']),\n",
       " WordList(['flesh', 'on']),\n",
       " WordList(['on', 'contact']),\n",
       " WordList(['contact', 'Snide']),\n",
       " WordList(['Snide', 'comparisons']),\n",
       " WordList(['comparisons', 'to']),\n",
       " WordList(['to', 'gelatin']),\n",
       " WordList(['gelatin', 'be']),\n",
       " WordList(['be', 'damned']),\n",
       " WordList(['damned', 'it']),\n",
       " WordList(['it', \"'s\"]),\n",
       " WordList([\"'s\", 'a']),\n",
       " WordList(['a', 'concept']),\n",
       " WordList(['concept', 'with']),\n",
       " WordList(['with', 'the']),\n",
       " WordList(['the', 'most']),\n",
       " WordList(['most', 'devastating']),\n",
       " WordList(['devastating', 'of']),\n",
       " WordList(['of', 'potential']),\n",
       " WordList(['potential', 'consequences']),\n",
       " WordList(['consequences', 'not']),\n",
       " WordList(['not', 'unlike']),\n",
       " WordList(['unlike', 'the']),\n",
       " WordList(['the', 'grey']),\n",
       " WordList(['grey', 'goo']),\n",
       " WordList(['goo', 'scenario']),\n",
       " WordList(['scenario', 'proposed']),\n",
       " WordList(['proposed', 'by']),\n",
       " WordList(['by', 'technological']),\n",
       " WordList(['technological', 'theorists']),\n",
       " WordList(['theorists', 'fearful']),\n",
       " WordList(['fearful', 'of']),\n",
       " WordList(['of', 'artificial']),\n",
       " WordList(['artificial', 'intelligence']),\n",
       " WordList(['intelligence', 'run']),\n",
       " WordList(['run', 'rampant'])]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ngrams \"the moving window\"\n",
    "# why ngrams?\n",
    "blob.ngrams(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WordList(['The', 'titular', 'threat']),\n",
       " WordList(['titular', 'threat', 'of']),\n",
       " WordList(['threat', 'of', 'The']),\n",
       " WordList(['of', 'The', 'Blob']),\n",
       " WordList(['The', 'Blob', 'has']),\n",
       " WordList(['Blob', 'has', 'always']),\n",
       " WordList(['has', 'always', 'struck']),\n",
       " WordList(['always', 'struck', 'me']),\n",
       " WordList(['struck', 'me', 'as']),\n",
       " WordList(['me', 'as', 'the']),\n",
       " WordList(['as', 'the', 'ultimate']),\n",
       " WordList(['the', 'ultimate', 'movie']),\n",
       " WordList(['ultimate', 'movie', 'monster']),\n",
       " WordList(['movie', 'monster', 'an']),\n",
       " WordList(['monster', 'an', 'insatiably']),\n",
       " WordList(['an', 'insatiably', 'hungry']),\n",
       " WordList(['insatiably', 'hungry', 'amoeba-like']),\n",
       " WordList(['hungry', 'amoeba-like', 'mass']),\n",
       " WordList(['amoeba-like', 'mass', 'able']),\n",
       " WordList(['mass', 'able', 'to']),\n",
       " WordList(['able', 'to', 'penetrate']),\n",
       " WordList(['to', 'penetrate', 'virtually']),\n",
       " WordList(['penetrate', 'virtually', 'any']),\n",
       " WordList(['virtually', 'any', 'safeguard']),\n",
       " WordList(['any', 'safeguard', 'capable']),\n",
       " WordList(['safeguard', 'capable', 'of']),\n",
       " WordList(['capable', 'of', 'as']),\n",
       " WordList(['of', 'as', 'a']),\n",
       " WordList(['as', 'a', 'doomed']),\n",
       " WordList(['a', 'doomed', 'doctor']),\n",
       " WordList(['doomed', 'doctor', 'chillingly']),\n",
       " WordList(['doctor', 'chillingly', 'describes']),\n",
       " WordList(['chillingly', 'describes', 'it']),\n",
       " WordList(['describes', 'it', 'assimilating']),\n",
       " WordList(['it', 'assimilating', 'flesh']),\n",
       " WordList(['assimilating', 'flesh', 'on']),\n",
       " WordList(['flesh', 'on', 'contact']),\n",
       " WordList(['on', 'contact', 'Snide']),\n",
       " WordList(['contact', 'Snide', 'comparisons']),\n",
       " WordList(['Snide', 'comparisons', 'to']),\n",
       " WordList(['comparisons', 'to', 'gelatin']),\n",
       " WordList(['to', 'gelatin', 'be']),\n",
       " WordList(['gelatin', 'be', 'damned']),\n",
       " WordList(['be', 'damned', 'it']),\n",
       " WordList(['damned', 'it', \"'s\"]),\n",
       " WordList(['it', \"'s\", 'a']),\n",
       " WordList([\"'s\", 'a', 'concept']),\n",
       " WordList(['a', 'concept', 'with']),\n",
       " WordList(['concept', 'with', 'the']),\n",
       " WordList(['with', 'the', 'most']),\n",
       " WordList(['the', 'most', 'devastating']),\n",
       " WordList(['most', 'devastating', 'of']),\n",
       " WordList(['devastating', 'of', 'potential']),\n",
       " WordList(['of', 'potential', 'consequences']),\n",
       " WordList(['potential', 'consequences', 'not']),\n",
       " WordList(['consequences', 'not', 'unlike']),\n",
       " WordList(['not', 'unlike', 'the']),\n",
       " WordList(['unlike', 'the', 'grey']),\n",
       " WordList(['the', 'grey', 'goo']),\n",
       " WordList(['grey', 'goo', 'scenario']),\n",
       " WordList(['goo', 'scenario', 'proposed']),\n",
       " WordList(['scenario', 'proposed', 'by']),\n",
       " WordList(['proposed', 'by', 'technological']),\n",
       " WordList(['by', 'technological', 'theorists']),\n",
       " WordList(['technological', 'theorists', 'fearful']),\n",
       " WordList(['theorists', 'fearful', 'of']),\n",
       " WordList(['fearful', 'of', 'artificial']),\n",
       " WordList(['of', 'artificial', 'intelligence']),\n",
       " WordList(['artificial', 'intelligence', 'run']),\n",
       " WordList(['intelligence', 'run', 'rampant'])]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.ngrams(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList([u'titular threat', 'blob', u'ultimate movie monster', u'amoeba-like mass', 'snide', u'potential consequences', u'grey goo scenario', u'technological theorists fearful', u'artificial intelligence run rampant'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# interesting\n",
    "blob.noun_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "going\n",
      "went\n",
      "is\n",
      "wa\n",
      "be\n"
     ]
    }
   ],
   "source": [
    "# lemma\n",
    "new_blob = TextBlob(\"going went is was be\")\n",
    "for word in new_blob.words:\n",
    "    print word.lemmatize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go\n",
      "go\n",
      "be\n",
      "be\n",
      "be\n"
     ]
    }
   ],
   "source": [
    "# oh-oh problem! \n",
    "for word in new_blob.words:\n",
    "    print word.lemmatize(\"v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word.lemmatize?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# lemmas need part of speech!\n",
    "import nltk\n",
    "\n",
    "# runs nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', u'DT'),\n",
       " ('titular', u'JJ'),\n",
       " ('threat', u'NN'),\n",
       " ('of', u'IN'),\n",
       " ('The', u'DT'),\n",
       " ('Blob', u'NNP'),\n",
       " ('has', u'VBZ'),\n",
       " ('always', u'RB'),\n",
       " ('struck', u'VBN'),\n",
       " ('me', u'PRP'),\n",
       " ('as', u'IN'),\n",
       " ('the', u'DT'),\n",
       " ('ultimate', u'JJ'),\n",
       " ('movie', u'NN'),\n",
       " ('monster', u'NN'),\n",
       " ('an', u'DT'),\n",
       " ('insatiably', u'RB'),\n",
       " ('hungry', u'JJ'),\n",
       " ('amoeba-like', u'JJ'),\n",
       " ('mass', u'NN'),\n",
       " ('able', u'JJ'),\n",
       " ('to', u'TO'),\n",
       " ('penetrate', u'VB'),\n",
       " ('virtually', u'RB'),\n",
       " ('any', u'DT'),\n",
       " ('safeguard', u'NN'),\n",
       " ('capable', u'JJ'),\n",
       " ('of', u'IN'),\n",
       " ('as', u'IN'),\n",
       " ('a', u'DT'),\n",
       " ('doomed', u'JJ'),\n",
       " ('doctor', u'NN'),\n",
       " ('chillingly', u'RB'),\n",
       " ('describes', u'VBZ'),\n",
       " ('it', u'PRP'),\n",
       " ('assimilating', u'VBG'),\n",
       " ('flesh', u'NN'),\n",
       " ('on', u'IN'),\n",
       " ('contact', u'NN'),\n",
       " ('Snide', u'JJ'),\n",
       " ('comparisons', u'NNS'),\n",
       " ('to', u'TO'),\n",
       " ('gelatin', u'VB'),\n",
       " ('be', u'VB'),\n",
       " ('damned', u'VBN'),\n",
       " ('it', u'PRP'),\n",
       " (\"'s\", u'VBZ'),\n",
       " ('a', u'DT'),\n",
       " ('concept', u'NN'),\n",
       " ('with', u'IN'),\n",
       " ('the', u'DT'),\n",
       " ('most', u'RBS'),\n",
       " ('devastating', u'JJ'),\n",
       " ('of', u'IN'),\n",
       " ('potential', u'JJ'),\n",
       " ('consequences', u'NNS'),\n",
       " ('not', u'RB'),\n",
       " ('unlike', u'IN'),\n",
       " ('the', u'DT'),\n",
       " ('grey', u'NN'),\n",
       " ('goo', u'NN'),\n",
       " ('scenario', u'NN'),\n",
       " ('proposed', u'VBN'),\n",
       " ('by', u'IN'),\n",
       " ('technological', u'JJ'),\n",
       " ('theorists', u'NNS'),\n",
       " ('fearful', u'NN'),\n",
       " ('of', u'IN'),\n",
       " ('artificial', u'JJ'),\n",
       " ('intelligence', u'NN'),\n",
       " ('run', u'NN'),\n",
       " ('rampant', u'NN')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tagging is hard. this will take a while.\n",
    "blob.tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tags = new_blob.tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of tuples\n",
    "type(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'list_item[1]'\n"
     ]
    },
    {
     "ename": "MissingCorpusError",
     "evalue": "\nLooks like you are missing some required data for this feature.\n\nTo download the necessary data, simply run\n\n    python -m textblob.download_corpora\n\nor use the NLTK downloader to download the missing data: http://nltk.org/data.html\nIf this doesn't fix the problem, file an issue at https://github.com/sloria/TextBlob/issues.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mMissingCorpusError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-0d0e3bbf779b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlist_item\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnew_blob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mlist_item\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'list_item[1]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/textblob/decorators.pyc\u001b[0m in \u001b[0;36mdecorated\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMissingCorpusError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMissingCorpusError\u001b[0m: \nLooks like you are missing some required data for this feature.\n\nTo download the necessary data, simply run\n\n    python -m textblob.download_corpora\n\nor use the NLTK downloader to download the missing data: http://nltk.org/data.html\nIf this doesn't fix the problem, file an issue at https://github.com/sloria/TextBlob/issues.\n"
     ]
    }
   ],
   "source": [
    "# hmmm, why do you think is this not working?\n",
    "# look up wordnet vs. treebank parts of speech\n",
    "for list_item in new_blob.tags:\n",
    "    list_item[0].lemmatize('list_item[1]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "# booooring\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VBG v\n",
      "VBD v\n",
      "VBZ v\n",
      "VBD v\n",
      "VB v\n"
     ]
    }
   ],
   "source": [
    "lemmas = ()\n",
    "# ok this seems to work\n",
    "for list_item in new_blob.tags:\n",
    "    word = list_item[0]\n",
    "    tpos = list_item[1]\n",
    "    wpos = get_wordnet_pos(tpos)\n",
    "    print tpos, wpos\n",
    "    \n",
    "    #lemmas.append(list_item[0].lemmatize(get_wordent_pos(list_item[1]))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'go', u'go', u'be', u'be', 'be']\n"
     ]
    }
   ],
   "source": [
    "lemmas = []\n",
    "# lets make it better\n",
    "for list_item in new_blob.tags:\n",
    "    word = list_item[0]\n",
    "    tpos = list_item[1]\n",
    "    wpos = get_wordnet_pos(tpos)\n",
    "    lemmas.append(word.lemmatize(wpos))\n",
    "    \n",
    "print lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This text is about:\n",
      "tables\n",
      "cottons\n",
      "places\n",
      "exchanges\n",
      "covers\n"
     ]
    }
   ],
   "source": [
    "# ported from Allison Parish's excellent\n",
    "# http://rwet.decontextualize.com/book/textblob/\n",
    "\n",
    "# let's make a simple text summary\n",
    "from textblob import TextBlob, Word\n",
    "import random\n",
    "\n",
    "# From Tender Buttons by Gertrude Stein\n",
    "text = '''\n",
    "A cushion has that cover. Supposing you do not like to change, supposing it is very clean \n",
    "that there is no change in appearance, supposing that there is regularity and a costume is \n",
    "that any the worse than an oyster and an exchange. Come to season that is there any extreme \n",
    "use in feather and cotton. Is there not much more joy in a table and more chairs and very \n",
    "likely roundness and a place to put them. A circle of fine card board and a chance to see a tassel. \n",
    "'''\n",
    "\n",
    "blob = TextBlob(text)\n",
    "\n",
    "nouns = list()\n",
    "for word, tag in blob.tags:\n",
    "    if tag == 'NN':\n",
    "        nouns.append(word.lemmatize())\n",
    "\n",
    "print \"This text is about:\"\n",
    "for item in random.sample(nouns, 5):\n",
    "    word = Word(item)\n",
    "    print word.pluralize()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "name": "python",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
